# -*- coding: utf-8 -*-
"""Metodos.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/19owruX6AHuZQePPwuP-FQj5uloD7ZzHD
"""

pip install streamlit

import yfinance as yf
from datetime import datetime
import numpy as np
from scipy.stats import kurtosis, skew, norm, t
import pandas as pd
import streamlit as st
import plotly.express as px
import matplotlib.pyplot as plt

"""a) Descarga de datos de un activo financiero desde 2010"""

# Obtener la fecha de hoy en formato YYYY-MM-DD
hoy = datetime.today().strftime('%Y-%m-%d')

df = yf.download('^DJI', start='2010-01-01', end=hoy, progress=False)
df

"""b) Rendimientos diarios"""

rendimiento_simple = df["Close"].pct_change().dropna()
#rendimiento_simple

media = np.mean(rendimiento_simple)
sesgo = skew(rendimiento_simple)
desviacion = np.std(rendimiento_simple)
exceso_curtosis = kurtosis(rendimiento_simple) - 3

estadisticas_simple = pd.DataFrame({'Media': [media],"Desviación":[desviacion] ,'Sesgo': [sesgo], 'Exceso de curtosis': [exceso_curtosis]},index=['Estadísticas'])

# Mostrar resultados
print(estadisticas_simple)

rendimiento_log = np.log(df["Close"]).diff().dropna()
#rendimiento_log

media_log = np.mean(rendimiento_log)
sesgo_log = skew(rendimiento_log)
desviacion_log = np.std(rendimiento_log)
exceso_curtosis_log = kurtosis(rendimiento_log) - 3

estadisticas_simple = pd.DataFrame({'Media': [media_log], 'Sesgo': [sesgo_log], "Desviación":[desviacion_log],'Exceso de curtosis': [exceso_curtosis_log]},index=['Estadísticas'])

# Mos<trar resultados
print(estadisticas_simple)

"""c) Calcula el VaR y ES para la serie completa de datos a los siguientes intervalos de confianza:

α = 0,95, 0,975, y 0,99

bajo una aproximacion paramétrica asumiendo una distribución normal y t-
student, además bajo una aproximación histórica y Monte Carlo. Muestra tus resultados en una tabla en el reporte.
"""

VaR_normal, ES_normal = [], []
VaR_t, ES_t = [], []
hVaR, hES = [], []
VaR_m, ES_m = [], []

for alfa in [0.95, 0.975, 0.99]:
    # Normal
    var = norm.ppf(1 - alfa, media_log, desviacion_log)
    es = rendimiento_log[rendimiento_log <= var].mean()
    if isinstance(es, (pd.Series, np.ndarray)):
        es = es.values[0]
    VaR_normal.append(var)
    ES_normal.append(es)

    # T-Student
    var = t.ppf(1 - alfa, len(rendimiento_log) - 1) * desviacion_log + media_log
    if isinstance(var, (pd.Series, np.ndarray)):
        var = var.values[0]
    es = rendimiento_log[rendimiento_log <= var].mean()
    if isinstance(es, (pd.Series, np.ndarray)):
        es = es.values[0]
    VaR_t.append(var)
    ES_t.append(es)

    # Histórico
    var = rendimiento_log.quantile(1 - alfa)
    if isinstance(var, (pd.Series, np.ndarray)):
        var = var.values[0]
    es = rendimiento_log[rendimiento_log <= var].mean()
    if isinstance(es, (pd.Series, np.ndarray)):
        es = es.values[0]
    hVaR.append(var)
    hES.append(es)

    # MonteCarlo
    n = 100000
    simulaciones = np.random.normal(media_log, desviacion_log, n)
    var = np.percentile(simulaciones, (1 - alfa) * 100)
    es = rendimiento_log[rendimiento_log <= var].mean()
    if isinstance(es, (pd.Series, np.ndarray)):
        es = es.values[0]
    VaR_m.append(var)
    ES_m.append(es)

# Crear DataFrame con los resultados
resultados = pd.DataFrame({
    "Nivel de Confianza": [0.95, 0.975, 0.99],
    "VaR_Normal": VaR_normal,
    "ES_Normal": ES_normal,
    "VaR_t": VaR_t,
    "ES_t": ES_t,
    "VaR_Historico": hVaR,
    "ES_Historico": hES,
    "VaR_MonteCarlo": VaR_m,
    "ES_MonteCarlo": ES_m
}).set_index("Nivel de Confianza")

from IPython.display import display # Asegúrate de importar display

# ... (tu código existente) ...

# Mostrar resultados como tabla
display(resultados)

"""d) En el mercado, el VaR y el ES son las medidas populares para medir el riesgo de una cartera o un activo, sin embargo, es común ver que usan rolling windows, i.e. fijar una ventana de X días y con esos datos calcular el VaR o ES del día X + 1, ejemplo: con una ventana de 252 retornos (r1, r2, ..., r252) calculas el VaRα asociado al retorno 253, ahora el VaRα asociado al retorno 254 viene del conjunto de datos (r2, r3, ..., r253), etc. Con esto en mente en una sola gráfica muestra las ganancias y pérdidas además del VaR y el ES con α = 0,95 y 0,99 con una rolling window de 252 retornos (debe de ser una serie de tiempo) y sobre todo recuerda que el VaRtα es calculado con los retornos r1, r2, ..., r252 y busca predecir el retorno r253, y el V aRt+1α calculado con los retornos r2, r3, ..., r253 busca predecir el retorno r254, etc. Asegurate que tu codigo realice esta grafica ademas de ponerla en el Streamlit La estimación del VaR y ES debe de ser hist́orico y paramétrico (puedes asumir una distribución normal por practicidad), recuerda el ejemplo que se vio en clase.

def rolling_window(rendimiento, window=252):
    alfas = [0.95, 0.99]

    # Diccionario para almacenar resultados
    resultados = {
        "Fecha": [],
        "VaR_95_h": [], "TVaR_95_h": [],
        "VaR_99_h": [], "TVaR_99_h": [],
        "VaR_95_n": [], "TVaR_95_n": [],
        "VaR_99_n": [], "TVaR_99_n": [],
    }

    for t in range(window, len(rendimiento)):
      datos_window = rendimiento.iloc[t-window:t].dropna()
      if len(datos_window) < window:
        raise ValueError(f"No hay suficientes datos. Se requieren minimo {window}, pero solo hay {len(datos_window)}.")
      else:
        media = datos_window.mean()
        desviacion = datos_window.std()

        #Fecha actual y rendimiento real
        fecha_actual = rendimiento.index[t]
        rendimiento_real = rendimiento.iloc[t]

        #VaR y TVaR Histórico
        var_h95 = datos_window.quantile(1 - 0.95)
        var_h99 = datos_window.quantile(1 - 0.99)
        tvar_h95 = datos_window[datos_window <= var_h95].mean()
        tvar_h99 = datos_window[datos_window <= var_h99].mean()


        #VaR y TVaR Normal
        var_n95 = norm.ppf(1 - 0.95, media, desviacion)
        var_n99 = norm.ppf(1 - 0.99, media, desviacion)

        var_n95 = var_n95.item() if isinstance(var_n95, (np.ndarray, pd.Series)) else var_n95
        var_n99 = var_n99.item() if isinstance(var_n99, (np.ndarray, pd.Series)) else var_n99

        tvar_n95 = datos_window[datos_window <= var_n95].mean()
        tvar_n99 = datos_window[datos_window <= var_n99].mean()

        convertir = [var_h95, var_h99, tvar_h95, tvar_h99, tvar_n95, tvar_n99]
        convertir = [j.values[0] if isinstance(j, (pd.Series, np.ndarray)) and hasattr(j, 'values') else j for j in convertir]

        # Asignar nuevamente a las variables originales
        var_h95, var_h99, tvar_h95, tvar_h99, tvar_n95, tvar_n99 = convertir

        # Almacenar resultados
        resultados["Fecha"].append(fecha_actual)
        resultados["VaR_95_h"].append(var_h95)
        resultados["TVaR_95_h"].append(tvar_h95)
        resultados["VaR_99_h"].append(var_h99)
        resultados["TVaR_99_h"].append(tvar_h99)
        resultados["VaR_95_n"].append(var_n95)
        resultados["TVaR_95_n"].append(tvar_n95)
        resultados["VaR_99_n"].append(var_n99)
        resultados["TVaR_99_n"].append(tvar_n99)

    #Convertir los resultados en un DataFrame
    df_resultados = pd.DataFrame(resultados).set_index("Fecha")

    # Graficar resultados
    plt.figure(figsize=(12, 6))
    plt.plot(df_resultados.index, rendimiento.loc[df_resultados.index], label="Rendimiento Logarítmico", color="black")
    plt.plot(df_resultados.index, df_resultados["VaR_95_n"], label="VaR 95% (Normal)", linestyle="--", color="blue")
    plt.plot(df_resultados.index, df_resultados["VaR_99_n"], label="VaR 99% (Normal)", linestyle="--", color="red")
    plt.plot(df_resultados.index, df_resultados["TVaR_95_n"], label="TVaR 95% (Normal)", linestyle=":", color="blue")
    plt.plot(df_resultados.index, df_resultados["TVaR_99_n"], label="TVaR 99% (Normal)", linestyle=":", color="red")
    plt.plot(df_resultados.index, df_resultados["VaR_95_h"], label="VaR 95% (Normal)", linestyle="--", color="magenta")
    plt.plot(df_resultados.index, df_resultados["VaR_99_h"], label="VaR 99% (Normal)", linestyle="--", color="purple")
    plt.plot(df_resultados.index, df_resultados["TVaR_95_h"], label="TVaR 95% (Normal)", linestyle=":", color="magenta")
    plt.plot(df_resultados.index, df_resultados["TVaR_99_h"], label="TVaR 99% (Normal)", linestyle=":", color="purple")
    plt.legend()
    plt.title("Rollin window")
    plt.xlabel("Fecha")
    plt.ylabel("Valor")
    plt.grid(True)
    plt.show()

    return df_resultados
"""

def rolling_window(rendimiento, window=252):
    niveles_confianza = np.arange(0.90, 0.991, 0.01)  # Pasos de 0.01 (90% a 99%)
    resultados = { "Fecha": [] }

    # Inicializar columnas para cada nivel de confianza
    for alfa in niveles_confianza:
        resultados[f"VaR_{int(alfa*100)}_h"] = []
        resultados[f"TVaR_{int(alfa*100)}_h"] = []
        resultados[f"VaR_{int(alfa*100)}_n"] = []
        resultados[f"TVaR_{int(alfa*100)}_n"] = []

    for t in range(window, len(rendimiento)):
        datos_window = rendimiento.iloc[t-window:t].dropna()
        if len(datos_window) < window:
            continue

        media = datos_window.mean()
        desviacion = datos_window.std()
        fecha_actual = rendimiento.index[t]

        resultados["Fecha"].append(fecha_actual)

        for alfa in niveles_confianza:
            # Histórico
            var_h = np.asarray(datos_window.quantile(1 - alfa)).item()
            tvar_h = np.asarray(datos_window[datos_window <= var_h].mean()).item()


            # Normal
            var_n = np.asarray(norm.ppf(1 - alfa, media, desviacion)).item()
            tvar_n = np.asarray(datos_window[datos_window <= var_n].mean()).item()

            # Convertir valores si son series o arrays
            for var in [var_h, tvar_h, var_n, tvar_n]:
                if isinstance(var, (np.ndarray, pd.Series)):
                    var = var.item()



            # Guardar resultados
            resultados[f"VaR_{int(alfa*100)}_h"].append(var_h)
            resultados[f"TVaR_{int(alfa*100)}_h"].append(tvar_h)
            resultados[f"VaR_{int(alfa*100)}_n"].append(var_n)
            resultados[f"TVaR_{int(alfa*100)}_n"].append(tvar_n)

    return pd.DataFrame(resultados).set_index("Fecha")

r = rolling_window(rendimiento_log)

r

"""e) Violaciones"""

def violaciones(df_resultados, rendimiento):
  columnas_relevantes = [
        "VaR_95_h", "VaR_99_h", "TVaR_95_h", "TVaR_99_h",
        "VaR_95_n", "VaR_99_n", "TVaR_95_n", "TVaR_99_n"
    ]
  df_resultados = df_resultados[columnas_relevantes]

  n = len(df_resultados)

  #contadores
  conteo_violaciones = {
      "Violaciones_VaR_95_h": 0, "Violaciones_VaR_99_h": 0,
      "Violaciones_TVaR_95_h": 0, "Violaciones_TVaR_99_h": 0,
      "Violaciones_VaR_95_n": 0, "Violaciones_VaR_99_n": 0,
      "Violaciones_TVaR_95_n": 0, "Violaciones_TVaR_99_n": 0
  }

  for fecha in df_resultados.index:
    rendimiento_real = rendimiento.loc[fecha]

    var_h95, var_h99 = df_resultados.loc[fecha, ["VaR_95_h", "VaR_99_h"]]
    tvar_h95, tvar_h99 = df_resultados.loc[fecha, ["TVaR_95_h", "TVaR_99_h"]]
    var_n95, var_n99 = df_resultados.loc[fecha, ["VaR_95_n", "VaR_99_n"]]
    tvar_n95, tvar_n99 = df_resultados.loc[fecha, ["TVaR_95_n", "TVaR_99_n"]]

    #Sumar violaciones
    conteo_violaciones["Violaciones_VaR_95_h"] += 1 if rendimiento_real.item() < var_h95 else 0
    conteo_violaciones["Violaciones_VaR_99_h"] += 1 if rendimiento_real.item() < var_h99 else 0
    conteo_violaciones["Violaciones_TVaR_95_h"] += 1 if rendimiento_real.item() < tvar_h95 else 0
    conteo_violaciones["Violaciones_TVaR_99_h"] += 1 if rendimiento_real.item() < tvar_h99 else 0
    conteo_violaciones["Violaciones_VaR_95_n"] += 1 if rendimiento_real.item() < var_n95 else 0
    conteo_violaciones["Violaciones_VaR_99_n"] += 1 if rendimiento_real.item() < var_n99 else 0
    conteo_violaciones["Violaciones_TVaR_95_n"] += 1 if rendimiento_real.item() < tvar_n95 else 0
    conteo_violaciones["Violaciones_TVaR_99_n"] += 1 if rendimiento_real.item() < tvar_n99 else 0

  #porcentaje
  porcentaje_violaciones = {k: (v / n) * 100 for k, v in conteo_violaciones.items()} #k violaciones por caso, v la suma

  # Crear DataFrame
  df_porcentaje_violaciones = pd.DataFrame([porcentaje_violaciones])

  return df_porcentaje_violaciones

s = violaciones(r, rendimiento_log)

s

"""f)"""

def var_volatilidad_movil(rendimiento, window=252):
    alfas = [0.95, 0.99]
    resultados = {
        "Fecha": [],
        "VaR_95_m": [],
        "VaR_99_m": []
    }

    for t in range(window, len(rendimiento)):
        datos_window = rendimiento.iloc[t-window:t].dropna()
        if len(datos_window) < window:
            raise ValueError(f"No hay suficientes datos. Se requieren mínimo {window}, pero solo hay {len(datos_window)}.")

        desviacion = datos_window.std()
        fecha_actual = rendimiento.index[t]

        # Cálculo de VaR con volatilidad móvil y distribución normal
        var_m95 = norm.ppf(1 - 0.95) * desviacion
        var_m99 = norm.ppf(1 - 0.99) * desviacion

        resultados["Fecha"].append(fecha_actual)
        resultados["VaR_95_m"].append(var_m95)
        resultados["VaR_99_m"].append(var_m99)

    df_resultados = pd.DataFrame(resultados).set_index("Fecha")

    return df_resultados




def violaciones_var_movil(df_resultados, rendimiento):
    n = len(df_resultados)
    conteo_violaciones = {
        "Violaciones_VaR_95_m": 0,
        "Violaciones_VaR_99_m": 0
    }

    for fecha in df_resultados.index:
        rendimiento_real = rendimiento.loc[fecha].squeeze()
        rendimiento_real = rendimiento_real.item() if isinstance(rendimiento_real, (np.ndarray, pd.Series)) else rendimiento_real

        var_m95, var_m99 = df_resultados.loc[fecha, ["VaR_95_m", "VaR_99_m"]].values
        var_m95 = var_m95.item() if isinstance(var_m95, (np.ndarray, pd.Series)) else var_m95
        var_m99 = var_m99.item() if isinstance(var_m99, (np.ndarray, pd.Series)) else var_m99

        conteo_violaciones["Violaciones_VaR_95_m"] += 1 if rendimiento_real < var_m95 else 0
        conteo_violaciones["Violaciones_VaR_99_m"] += 1 if rendimiento_real < var_m99 else 0

    porcentaje_violaciones = {k: (v / n) * 100 for k, v in conteo_violaciones.items()}

    return pd.DataFrame([porcentaje_violaciones])

vol = var_volatilidad_movil(rendimiento_log)
vio = violaciones_var_movil(vol, rendimiento_log)

plt.figure(figsize=(12, 6))
plt.plot(vol.index, rendimiento_log.loc[vol.index], label="Rendimientos", color="black", alpha=0.6)
plt.plot(vol.index, vol["VaR_95_m"], label="VaR 95%", linestyle="--", color="cyan")
plt.plot(vol.index, vol["VaR_99_m"], label="VaR 99%", linestyle="--", color="red")
plt.legend()
plt.title("Volatilidad Móvil - Rolling Window 252 días")
plt.xlabel("Fecha")
plt.ylabel("Valor")
plt.show()

st.title("Aproximación de rendimientos")  # Título grande
st.markdown("<h2 style='font-size: 24px;'>Dow Jones</h2>", unsafe_allow_html=True)

#PRECIOS DE CIERRE
st.write("Los precios de cierre registrados desde 2010 a hoy han tenido el siguiente comportamiento:")
st.subheader("Gráfico de Precios Simulados")
st.line_chart(df['Close'])

#RENDIMIENTOS
st.write("Teniendo como rendimientos:")
st.subheader("Rendimientos logarítmicos")
st.line_chart(rendimiento_log)

#RESULTADOS DE VAR Y TVAR
st.write("Al calcular el VaR y TVaR de los rendimientos logarítmicos asumiendo una distribución normal, por MonteCarlo y con los datos históricos:")
st.subheader("Resultados de VaR y TVaR")
st.dataframe(resultados)

# Gráfico interactivo con selección de métricas
opciones = list(resultados.columns)
seleccion = st.multiselect("Selecciona las métricas a graficar", opciones, default=opciones)

if seleccion:
    df_filtrado = resultados[seleccion].astype(float)
    fig = px.line(df_filtrado, x=df_filtrado.index, y=df_filtrado.columns,
                  markers=True, title="Comparación de VaR y ES por Método")
    st.plotly_chart(fig)

#GRAFICAR ROLLING WINDOW
st.subheader("Análisis de VaR y TVaR con Rolling Window")

nivel_confianza = st.slider("Selecciona el nivel de confianza", 0.90, 0.99,0.95, 0.01)  # Slider con pasos de 1.5% (0.90 a 0.99)
nivel_confianza_str = str(int(nivel_confianza * 100))

metodo = st.radio("Selecciona el método", ["Normal", "Histórico", "Superpuesto"])  # Selección del método

# Filtrar datos según selección
cols_n = [f"VaR_{nivel_confianza_str}_n", f"TVaR_{nivel_confianza_str}_n"]
cols_h = [f"VaR_{nivel_confianza_str}_h", f"TVaR_{nivel_confianza_str}_h"]

if metodo == "Normal":
    df_filtrado = r[cols_n]
elif metodo == "Histórico":
    df_filtrado = r[cols_h]
else:
    df_filtrado = r[cols_n + cols_h]  # Superpuesto

# Gráfico interactivo
fig = px.line(df_filtrado, x=df_filtrado.index, y=df_filtrado.columns, markers=True,
              title=f"VaR y TVaR - {metodo} ({nivel_confianza*100}%)")

st.plotly_chart(fig)

#GRAFICAR Y EXPLICAR VIOLACIONES
st.write("Dadas las predicciones de los rendimientos con el VaR y TVaR, existen violaciones o errores entre el rendimiento real y su aproximado, calculadas como:")
st.latex("r_{253} < Va R_\alpha^t \text{ o } ES^t_\alpha")
st.subheader("Violaciones")
def resaltar_valores(val):
    color = 'background-color: red' if val > 2.5 else ''
    return color

styled_s = s.style.applymap(resaltar_valores)

st.dataframe(styled_s)

#VOLATILIDAD MOVIL
st.subheader("Análisis de VaR con Volatilidad Móvil")
# Mostrar DataFrame de VaR
st.subheader("Valores de VaR con Volatilidad Móvil")
st.dataframe(vol)

# Mostrar porcentaje de violaciones
st.subheader("Porcentaje de Violaciones")
st.dataframe(vio)

# Gráfica de VaR con Volatilidad Móvil
st.subheader("Gráfica de VaR con Volatilidad Móvil")
st.write("Es posible estimar el VaR con una volatilidad móvil a través de la fórmula:")
st.latex("Va R_{1-\alpha} = q_{\alpha} \times \sigma_t^{252}")
fig, ax = plt.subplots(figsize=(10, 5))
x_values = np.arange(len(vol.index))
y1_values = vol["VaR_95_m"].astype(float)
y2_values = vol["VaR_99_m"].astype(float)
ax.plot(x_values, y1_values, label="VaR 95% Móvil", color="blue")
ax.plot(x_values, y2_values, label="VaR 99% Móvil", color="red")
ax.fill_between(x_values, y1_values, y2_values, color="gray", alpha=0.3)
ax.set_title("VaR con Volatilidad Móvil")
ax.set_xlabel("Fecha")
ax.set_ylabel("VaR")
ax.set_xticks(x_values[::252])
ax.set_xticklabels(vol.index[::252].strftime('%Y-%m-%d'), rotation=45, ha='right')
ax.legend()
ax.grid()
st.pyplot(fig)

