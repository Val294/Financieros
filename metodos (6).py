# -*- coding: utf-8 -*-
"""Metodos.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/19owruX6AHuZQePPwuP-FQj5uloD7ZzHD
"""

import yfinance as yf
from datetime import datetime
import numpy as np
from scipy.stats import kurtosis, skew, norm, t
import pandas as pd
import streamlit as st
import plotly.express as px
import matplotlib.pyplot as plt

# Obtener la fecha de hoy en formato YYYY-MM-DD
hoy = datetime.today().strftime('%Y-%m-%d')

df = yf.download('^DJI', start='2010-01-01', end=hoy, progress=False)

rendimiento_simple = df["Close"].pct_change().dropna()
#rendimiento_simple

media = np.mean(rendimiento_simple)
sesgo = skew(rendimiento_simple)
desviacion = np.std(rendimiento_simple)
exceso_curtosis = kurtosis(rendimiento_simple) - 3

estadisticas_simple = pd.DataFrame({'Media': [media],"Desviación":[desviacion] ,'Sesgo': [sesgo], 'Exceso de curtosis': [exceso_curtosis]},index=['Estadísticas'])

rendimiento_log = np.log(df["Close"]).diff().dropna()

media_log = float(np.mean(rendimiento_log))
sesgo_log = float(skew(rendimiento_log))
desviacion_log = float(np.std(rendimiento_log))
exceso_curtosis_log = float(kurtosis(rendimiento_log) - 3)


#print(media_log, sesgo_log, desviacion_log, exceso_curtosis_log)

VaR_normal, ES_normal = [], []
VaR_t, ES_t = [], []
hVaR, hES = [], []
VaR_m, ES_m = [], []

for alfa in [0.95, 0.975, 0.99]:
    # Normal
    var = norm.ppf(1 - alfa, media_log, desviacion_log)
    es = rendimiento_log[rendimiento_log <= var].mean()
    if isinstance(es, (pd.Series, np.ndarray)):
        es = es.values[0]
    VaR_normal.append(var)
    ES_normal.append(es)

    # T-Student
    var = t.ppf(1 - alfa, len(rendimiento_log) - 1) * desviacion_log + media_log
    if isinstance(var, (pd.Series, np.ndarray)):
        var = var.values[0]
    es = rendimiento_log[rendimiento_log <= var].mean()
    if isinstance(es, (pd.Series, np.ndarray)):
        es = es.values[0]
    VaR_t.append(var)
    ES_t.append(es)

    # Histórico
    var = rendimiento_log.quantile(1 - alfa)
    if isinstance(var, (pd.Series, np.ndarray)):
        var = var.values[0]
    es = rendimiento_log[rendimiento_log <= var].mean()
    if isinstance(es, (pd.Series, np.ndarray)):
        es = es.values[0]
    hVaR.append(var)
    hES.append(es)

    # MonteCarlo
    n = 100000
    simulaciones = np.random.normal(media_log, desviacion_log, n)
    var = np.percentile(simulaciones, (1 - alfa) * 100)
    es = rendimiento_log[rendimiento_log <= var].mean()
    if isinstance(es, (pd.Series, np.ndarray)):
        es = es.values[0]
    VaR_m.append(var)
    ES_m.append(es)

# Crear DataFrame con los resultados
resultados = pd.DataFrame({
    "Nivel de Confianza": [0.95, 0.975, 0.99],
    "VaR_Normal": VaR_normal,
    "ES_Normal": ES_normal,
    "VaR_t": VaR_t,
    "ES_t": ES_t,
    "VaR_Historico": hVaR,
    "ES_Historico": hES,
    "VaR_MonteCarlo": VaR_m,
    "ES_MonteCarlo": ES_m
}).set_index("Nivel de Confianza")

def rolling_window(rendimiento, window=252):
    niveles_confianza = np.arange(0.90, 0.991, 0.01)  # Pasos de 0.01 (90% a 99%)
    resultados = { "Fecha": [] }

    # Inicializar columnas para cada nivel de confianza
    for alfa in niveles_confianza:
        resultados[f"VaR_{int(alfa*100)}_h"] = []
        resultados[f"TVaR_{int(alfa*100)}_h"] = []
        resultados[f"VaR_{int(alfa*100)}_n"] = []
        resultados[f"TVaR_{int(alfa*100)}_n"] = []

    for t in range(window, len(rendimiento)):
        datos_window = rendimiento.iloc[t-window:t].dropna()
        if len(datos_window) < window:
            continue

        media = datos_window.mean()
        desviacion = datos_window.std()
        fecha_actual = rendimiento.index[t]

        resultados["Fecha"].append(fecha_actual)

        for alfa in niveles_confianza:
            # Histórico
            var_h = np.asarray(datos_window.quantile(1 - alfa)).item()
            tvar_h = np.asarray(datos_window[datos_window <= var_h].mean()).item()


            # Normal
            var_n = np.asarray(norm.ppf(1 - alfa, media, desviacion)).item()
            tvar_n = np.asarray(datos_window[datos_window <= var_n].mean()).item()

            # Convertir valores si son series o arrays
            for var in [var_h, tvar_h, var_n, tvar_n]:
                if isinstance(var, (np.ndarray, pd.Series)):
                    var = var.item()



            # Guardar resultados
            resultados[f"VaR_{int(alfa*100)}_h"].append(var_h)
            resultados[f"TVaR_{int(alfa*100)}_h"].append(tvar_h)
            resultados[f"VaR_{int(alfa*100)}_n"].append(var_n)
            resultados[f"TVaR_{int(alfa*100)}_n"].append(tvar_n)

    return pd.DataFrame(resultados).set_index("Fecha")

r = rolling_window(rendimiento_log)

def violaciones(df_resultados, rendimiento):
  columnas_relevantes = [
        "VaR_95_h", "VaR_99_h", "TVaR_95_h", "TVaR_99_h",
        "VaR_95_n", "VaR_99_n", "TVaR_95_n", "TVaR_99_n"
    ]
  df_resultados = df_resultados[columnas_relevantes]

  n = len(df_resultados)

  #contadores
  conteo_violaciones = {
      "Violaciones_VaR_95_h": 0, "Violaciones_VaR_99_h": 0,
      "Violaciones_TVaR_95_h": 0, "Violaciones_TVaR_99_h": 0,
      "Violaciones_VaR_95_n": 0, "Violaciones_VaR_99_n": 0,
      "Violaciones_TVaR_95_n": 0, "Violaciones_TVaR_99_n": 0
  }

  for fecha in df_resultados.index:
    rendimiento_real = rendimiento.loc[fecha]

    var_h95, var_h99 = df_resultados.loc[fecha, ["VaR_95_h", "VaR_99_h"]]
    tvar_h95, tvar_h99 = df_resultados.loc[fecha, ["TVaR_95_h", "TVaR_99_h"]]
    var_n95, var_n99 = df_resultados.loc[fecha, ["VaR_95_n", "VaR_99_n"]]
    tvar_n95, tvar_n99 = df_resultados.loc[fecha, ["TVaR_95_n", "TVaR_99_n"]]

    #Sumar violaciones
    conteo_violaciones["Violaciones_VaR_95_h"] += 1 if rendimiento_real.item() < var_h95 else 0
    conteo_violaciones["Violaciones_VaR_99_h"] += 1 if rendimiento_real.item() < var_h99 else 0
    conteo_violaciones["Violaciones_TVaR_95_h"] += 1 if rendimiento_real.item() < tvar_h95 else 0
    conteo_violaciones["Violaciones_TVaR_99_h"] += 1 if rendimiento_real.item() < tvar_h99 else 0
    conteo_violaciones["Violaciones_VaR_95_n"] += 1 if rendimiento_real.item() < var_n95 else 0
    conteo_violaciones["Violaciones_VaR_99_n"] += 1 if rendimiento_real.item() < var_n99 else 0
    conteo_violaciones["Violaciones_TVaR_95_n"] += 1 if rendimiento_real.item() < tvar_n95 else 0
    conteo_violaciones["Violaciones_TVaR_99_n"] += 1 if rendimiento_real.item() < tvar_n99 else 0

  #porcentaje
  porcentaje_violaciones = {k: (v / n) * 100 for k, v in conteo_violaciones.items()} #k violaciones por caso, v la suma

  # Crear DataFrame
  df_porcentaje_violaciones = pd.DataFrame([porcentaje_violaciones])

  return df_porcentaje_violaciones

s = violaciones(r, rendimiento_log)

def var_volatilidad_movil(rendimiento, window=252):
    alfas = [0.95, 0.99]
    resultados = {
        "Fecha": [],
        "VaR_95_m": [],
        "VaR_99_m": []
    }

    for t in range(window, len(rendimiento)):
        datos_window = rendimiento.iloc[t-window:t].dropna()
        if len(datos_window) < window:
            raise ValueError(f"No hay suficientes datos. Se requieren mínimo {window}, pero solo hay {len(datos_window)}.")

        desviacion = datos_window.std()
        fecha_actual = rendimiento.index[t]

        # Cálculo de VaR con volatilidad móvil y distribución normal
        var_m95 = norm.ppf(1 - 0.95) * desviacion
        var_m99 = norm.ppf(1 - 0.99) * desviacion

        resultados["Fecha"].append(fecha_actual)
        resultados["VaR_95_m"].append(var_m95)
        resultados["VaR_99_m"].append(var_m99)

    df_resultados = pd.DataFrame(resultados).set_index("Fecha")

    return df_resultados




def violaciones_var_movil(df_resultados, rendimiento):
    n = len(df_resultados)
    conteo_violaciones = {
        "Violaciones_VaR_95_m": 0,
        "Violaciones_VaR_99_m": 0
    }

    for fecha in df_resultados.index:
        rendimiento_real = rendimiento.loc[fecha].squeeze()
        rendimiento_real = rendimiento_real.item() if isinstance(rendimiento_real, (np.ndarray, pd.Series)) else rendimiento_real

        var_m95, var_m99 = df_resultados.loc[fecha, ["VaR_95_m", "VaR_99_m"]].values
        var_m95 = var_m95.item() if isinstance(var_m95, (np.ndarray, pd.Series)) else var_m95
        var_m99 = var_m99.item() if isinstance(var_m99, (np.ndarray, pd.Series)) else var_m99

        conteo_violaciones["Violaciones_VaR_95_m"] += 1 if rendimiento_real < var_m95 else 0
        conteo_violaciones["Violaciones_VaR_99_m"] += 1 if rendimiento_real < var_m99 else 0

    porcentaje_violaciones = {k: (v / n) * 100 for k, v in conteo_violaciones.items()}

    return pd.DataFrame([porcentaje_violaciones])

vol = var_volatilidad_movil(rendimiento_log)
vio = violaciones_var_movil(vol, rendimiento_log)

plt.figure(figsize=(12, 6))
plt.plot(vol.index, rendimiento_log.loc[vol.index], label="Rendimientos", color="black", alpha=0.6)
plt.plot(vol.index, vol["VaR_95_m"], label="VaR 95%", linestyle="--", color="cyan")
plt.plot(vol.index, vol["VaR_99_m"], label="VaR 99%", linestyle="--", color="red")
plt.legend()
plt.title("Volatilidad Móvil - Rolling Window 252 días")
plt.xlabel("Fecha")
plt.ylabel("Valor")
plt.show()

st.title("Aproximación de rendimientos")  # Título grande
st.markdown("<h2 style='font-size: 24px;'>Dow Jones</h2>", unsafe_allow_html=True)

st.write("Dow Jones es uno de los índices bursátiles más influyentes de Estados Unidos, el cual se encarga de generar una variedad de índices creados por Charles Dow y Edward Jones, fundadores de Dow Jones & Company. Tenemos cinco principales índices que se nos brinda: Promedio Industrial Dow Jones, Promedio de Utilidades Dow Jones, Promedio de Transportes Dow Jones, Servicio de Empresas Servicios Públicos Dow Jones; para que una empresa empiece a ser considerada dentro de los índices debe representar una parte significativa de las actividades económicas en E.U. Se han incorporado empresas tan importantes como ferrocarrileras, petroleras, bancarias, farmacéuticas o tecnológicas. El Dow Jones fue pensado para ofrecer una perspectiva “simple” de la economía estadounidense. El índice se calcula sumando los precios de los 30 valores de la media y dividiéndolos por un divisor, divisor que se ha reducido a lo largo de los años esto para considerar sucesos imprevistos. La media está ponderada por el precio, lo que significa que cada empresa constituye una fracción del índice proporcional a su precio. Lo que nos dice que a mayores precios, mayor peso en su índice.")

#PRECIOS DE CIERRE
st.subheader("Gráfico de Precios Simulados")
st.write("Los precios de cierre registrados desde 2010 a hoy han tenido el siguiente comportamiento:")
st.line_chart(df['Close'])

#RENDIMIENTOS
st.subheader("Rendimientos logarítmicos")
st.write("Teniendo como rendimientos:")
st.line_chart(rendimiento_log)

#RESULTADOS DE VAR Y TVAR
st.subheader("Resultados de VaR y TVaR")
st.write("Al calcular el VaR y TVaR de los rendimientos logarítmicos asumiendo una distribución normal, por MonteCarlo y con los datos históricos:")
st.dataframe(resultados)

# Gráfico interactivo con selección de métricas
opciones = list(resultados.columns)
seleccion = st.multiselect("Selecciona las métricas a graficar", opciones, default=opciones)

if seleccion:
    df_filtrado = resultados[seleccion].astype(float)
    fig = px.line(df_filtrado, x=df_filtrado.index, y=df_filtrado.columns,
                  markers=True, title="Comparación de VaR y ES por Método")
    st.plotly_chart(fig)

#GRAFICAR ROLLING WINDOW
st.subheader("Análisis de VaR y TVaR con Rolling Window")

nivel_confianza = st.slider("Selecciona el nivel de confianza", 0.90, 0.99,0.95, 0.01)  # Slider con pasos de 1.5% (0.90 a 0.99)
nivel_confianza_str = str(int(nivel_confianza * 100))

metodo = st.radio("Selecciona el método", ["Normal", "Histórico", "Superpuesto"])  # Selección del método

# Filtrar datos según selección
cols_n = [f"VaR_{nivel_confianza_str}_n", f"TVaR_{nivel_confianza_str}_n"]
cols_h = [f"VaR_{nivel_confianza_str}_h", f"TVaR_{nivel_confianza_str}_h"]

if metodo == "Normal":
    df_filtrado = r[cols_n]
elif metodo == "Histórico":
    df_filtrado = r[cols_h]
else:
    df_filtrado = r[cols_n + cols_h]  # Superpuesto

# Gráfico interactivo
fig = px.line(df_filtrado, x=df_filtrado.index, y=df_filtrado.columns, markers=True,
              title=f"VaR y TVaR - {metodo} ({nivel_confianza*100}%)")

st.plotly_chart(fig)

#GRAFICAR Y EXPLICAR VIOLACIONES
st.write("Dadas las predicciones de los rendimientos con el VaR y TVaR, existen violaciones o errores entre el rendimiento real y su aproximado, calculadas como:")
st.latex(r"r_{253} < Va R_\alpha^t \text{ o } ES^t_\alpha")
st.subheader("Violaciones")
def resaltar_valores(val):
    color = 'background-color: red' if val > 2.5 else ''
    return color

styled_s = s.style.applymap(resaltar_valores)

st.dataframe(styled_s)

#VOLATILIDAD MOVIL
st.subheader("Análisis de VaR con Volatilidad Móvil")

# Mostrar porcentaje de violaciones
st.subheader("Porcentaje de Violaciones")
st.dataframe(vio)

# Gráfica de VaR con Volatilidad Móvil
st.subheader("Gráfica de VaR con Volatilidad Móvil")
st.write("Es posible estimar el VaR con una volatilidad móvil a través de la fórmula:")
st.latex(r"Va R_{1-\alpha} = q_{\alpha} \times \sigma_t^{252}")
fig, ax = plt.subplots(figsize=(10, 5))
x_values = np.arange(len(vol.index))
y1_values = vol["VaR_95_m"].astype(float)
y2_values = vol["VaR_99_m"].astype(float)
ax.plot(x_values, y1_values, label="VaR 95% Móvil", color="blue")
ax.plot(x_values, y2_values, label="VaR 99% Móvil", color="red")
ax.fill_between(x_values, y1_values, y2_values, color="gray", alpha=0.3)
ax.set_title("VaR con Volatilidad Móvil")
ax.set_xlabel("Fecha")
ax.set_ylabel("VaR")
ax.set_xticks(x_values[::252])
ax.set_xticklabels(vol.index[::252].strftime('%Y-%m-%d'), rotation=45, ha='right')
ax.legend()
ax.grid()
st.pyplot(fig)

